{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T21:08:12.099376Z",
     "start_time": "2025-12-10T21:08:02.472452Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "class SimpsonsCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpsonsCNN, self).__init__()\n",
    "        \n",
    "        def conv_block(in_c, out_c, pool=True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            if pool:\n",
    "                layers.append(nn.MaxPool2d(2))\n",
    "            return nn.Sequential(*layers)\n",
    "        \n",
    "        self.block1 = conv_block(3, 32)\n",
    "        self.block2 = conv_block(32, 64)\n",
    "        self.block3 = conv_block(64, 128)\n",
    "        self.block4 = conv_block(128, 256)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:08:12.268895Z",
     "start_time": "2025-12-10T21:08:12.117273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def infer(data_dir, model_path):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"INFERENCE MODE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Model: {model_path}\")\n",
    "    print(f\"Data directory: {data_dir}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"‚úó Model not found: {model_path}\")\n",
    "    \n",
    "    print(\"\\nüì¶ Loading model...\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    class_names = checkpoint['class_names']\n",
    "    img_size = checkpoint['config']['img_size']\n",
    "    \n",
    "    model = SimpsonsCNN(num_classes=len(class_names))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"‚úì Model loaded | Classes: {len(class_names)} | Image size: {img_size}x{img_size}\")\n",
    "    \n",
    "    infer_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    if not os.path.isdir(data_dir):\n",
    "        print(f\"‚úó Directory not found: {data_dir}\")\n",
    "        return\n",
    "    \n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "    file_list = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(valid_extensions):\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(full_path, data_dir)\n",
    "                file_list.append((full_path, rel_path))\n",
    "    \n",
    "    if len(file_list) == 0:\n",
    "        print(f\"‚úó No images found in {data_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüñºÔ∏è Found {len(file_list)} images\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = {}\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(\n",
    "            file_list,\n",
    "            desc=\"üìä Processing images\",\n",
    "            unit=\"img\",\n",
    "            bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {postfix}',\n",
    "            colour='green'\n",
    "        )\n",
    "        \n",
    "        for full_path, rel_path in pbar:\n",
    "            try:\n",
    "                image = Image.open(full_path).convert('RGB')\n",
    "                input_tensor = infer_transform(image).unsqueeze(0).to(device)\n",
    "                \n",
    "                outputs = model(input_tensor)\n",
    "                _, predicted_idx = torch.max(outputs, 1)\n",
    "                predicted_class = class_names[predicted_idx.item()]\n",
    "                \n",
    "                true_label = os.path.basename(os.path.dirname(full_path))\n",
    "                \n",
    "                results[rel_path] = {\n",
    "                    'predicted': predicted_class,\n",
    "                    'true_label': true_label\n",
    "                }\n",
    "                \n",
    "                if true_label in class_names:\n",
    "                    total += 1\n",
    "                    if predicted_class == true_label:\n",
    "                        correct += 1\n",
    "                \n",
    "                accuracy = (correct / total * 100) if total > 0 else 0\n",
    "                pbar.set_postfix({'pred': predicted_class[:12], 'acc': f'{accuracy:.1f}%'})\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è Skipping {rel_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    output_file = 'results.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"INFERENCE COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total images processed: {len(results)}\")\n",
    "    if total > 0:\n",
    "        print(f\"Accuracy: {correct}/{total} = {correct/total*100:.2f}%\")\n",
    "    print(f\"Results saved: {output_file}\")\n",
    "    print(\"=\"*80)"
   ],
   "id": "ca66097527ecdec6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiuStudnet\\PycharmProjects\\SpringField\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T21:08:50.744160Z",
     "start_time": "2025-12-10T21:08:12.682879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    infer('characters_train/bart_simpson', 'model.pth')\n",
    "    pass"
   ],
   "id": "2a3cc82bb7bb7ace",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INFERENCE MODE\n",
      "================================================================================\n",
      "Device: cpu\n",
      "Model: model.pth\n",
      "Data directory: characters_train/bart_simpson\n",
      "================================================================================\n",
      "\n",
      "üì¶ Loading model...\n",
      "‚úì Model loaded | Classes: 42 | Image size: 128x128\n",
      "\n",
      "üñºÔ∏è Found 1074 images\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìä Processing images: 100%|\u001B[32m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001B[0m| 1074/1074 [00:37<00:00, 28.35img/s] , pred=bart_simpson, acc=97.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ INFERENCE COMPLETE\n",
      "================================================================================\n",
      "Total images processed: 1074\n",
      "Accuracy: 1044/1074 = 97.21%\n",
      "Results saved: results.json\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
