{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AdaptiveAvgPool2d((4, 4)),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256 * 4 * 4, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, 1) # placeholder\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "id": "ca66097527ecdec6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def infer(data_dir, model_path):\n",
    "# load label map\n",
    "    label_map_path = 'label_map.json'\n",
    "    if not os.path.exists(label_map_path):\n",
    "        raise FileNotFoundError('label_map.json not found. Make sure train.ipynb saved it in cwd')\n",
    "    with open(label_map_path, 'r') as f:\n",
    "        label_map = json.load(f) # \"idx\": \"class_name\"\n",
    "    # convert keys to int (they were strings when dumped)\n",
    "        label_map = {int(k): v for k, v in label_map.items()}\n",
    "\n",
    "\n",
    "# load checkpoint\n",
    "    ckpt = torch.load(model_path, map_location=device)\n",
    "    class_to_idx = ckpt.get('class_to_idx')\n",
    "    if class_to_idx is None:\n",
    "        raise RuntimeError('Saved checkpoint missing class_to_idx')\n",
    "\n",
    "\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()} # ensure mapping\n",
    "    num_classes = len(idx_to_class)\n",
    "    \n",
    "    \n",
    "    # instantiate model and replace last layer to match saved num_classes\n",
    "    model = SimpleCNN(num_classes=1) # temporary\n",
    "    # reconstruct classifier final layer properly\n",
    "    model = SimpleCNN(num_classes=1) # features match; now patch classifier\n",
    "    # We'll create a fresh classifier with correct output dim\n",
    "    model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256 * 4 * 4, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    # transforms (use the same normalization/resize as training val)\n",
    "    img_size = ckpt.get('img_size', 128)\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "    data_dir = Path(data_dir)\n",
    "    images = [p for p in data_dir.iterdir() if p.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "    \n",
    "    \n",
    "    results = {}\n",
    "    with torch.no_grad():\n",
    "        for p in images:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            x = transform(img).unsqueeze(0).to(device)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=1).item()\n",
    "            cls_name = idx_to_class[pred]\n",
    "            results[p.name] = cls_name\n",
    "\n",
    "\n",
    "# save results.json\n",
    "    with open('results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "\n",
    "    print('Wrote results.json with', len(results), 'predictions')\n",
    "    return results"
   ],
   "id": "2a3cc82bb7bb7ace"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
